{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d5d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f391daac",
   "metadata": {},
   "source": [
    "# 0: Data Loading, Set Splitting Functions, Data Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82ef5792",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv('data/diabetes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ad06e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_diabetes(diabetes_df, test_size=0.2, random_state=42, stratify=True, resample=True) -> tuple:\n",
    "    \"\"\"\n",
    "    Returns a tuple of (X_train, X_test, y_train, y_test) for the diabetes dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    # Split the data into features and target variable\n",
    "    X = diabetes_df.drop(columns=['Outcome'])\n",
    "    y = diabetes_df['Outcome']\n",
    "    \n",
    "    # Split the dataset into training and testing sets\n",
    "    \n",
    "    if stratify:\n",
    "        return train_test_split(X, y, random_state=random_state, test_size=test_size, stratify=y)\n",
    "    else:\n",
    "        return train_test_split(X, y, random_state=random_state, test_size=0.2)\n",
    "    \n",
    "    \n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_diabetes(diabetes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec85ad17",
   "metadata": {},
   "source": [
    "# 1: Create Model and Pipeline Presets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d973631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_preprocessing_pipe(scaling = True, preprocessing = \"PCA\"):\n",
    "    \"\"\"\n",
    "    Returns a preprocessing pipeline with optional scaling and PCA/ICA.\n",
    "    \"\"\"\n",
    "    pipe = []\n",
    "    if preprocessing == \"PCA\":\n",
    "        pipe.append( ('PCA', PCA(n_components=2)) )\n",
    "    if preprocessing == \"ICA\":\n",
    "        pipe.append( \n",
    "                    ('ICA', FastICA(n_components=2))\n",
    "                    )\n",
    "    if scaling:\n",
    "        pipe.insert(0, ('Scaler', StandardScaler()))\n",
    "    return pipe\n",
    "\n",
    "def get_knn_pipe(base_pipe : List = None):\n",
    "    \"\"\"Returns a pipeline for KNN classifier with optional scaling and preprocessing.\"\"\"\n",
    "    pipe = [\n",
    "        ('KNN', KNeighborsClassifier(n_neighbors=5, algorithm='auto', n_jobs=-1))\n",
    "    ]\n",
    "    if base_pipe:\n",
    "        pipe = base_pipe + pipe\n",
    "    return Pipeline(pipe)\n",
    "    \n",
    "def get_naive_bayes_pipe(base_pipe : List = None):\n",
    "    \"\"\"Returns a pipeline for Naive Bayes classifier with optional scaling and preprocessing.\"\"\"\n",
    "    pipe = [\n",
    "        ('clf', GaussianNB())\n",
    "    ]\n",
    "    if base_pipe:\n",
    "        pipe = base_pipe + pipe\n",
    "    return Pipeline(pipe)\n",
    "\n",
    "def get_log_reg_pipe(base_pipe = None):\n",
    "    \"\"\"Returns a pipeline for Logistic Regression classifier with optional scaling and preprocessing.\"\"\"\n",
    "    pipe = [\n",
    "        ('LogisticRegression', LogisticRegression(max_iter=1000))\n",
    "    ]\n",
    "    if base_pipe:\n",
    "        pipe = base_pipe + pipe\n",
    "    return Pipeline(pipe)\n",
    "\n",
    "def get_decision_tree_pipe(base_pipe = None):\n",
    "    \"\"\"Returns a pipeline for Decision Tree classifier with optional scaling and preprocessing.\"\"\"\n",
    "    pipe = [\n",
    "        ('DecisionTree', DecisionTreeClassifier())\n",
    "    ]\n",
    "    if base_pipe:\n",
    "        pipe = base_pipe + pipe\n",
    "    return Pipeline(pipe)\n",
    "\n",
    "def get_svm_pipe(base_pipe = None):\n",
    "    \"\"\"Returns a pipeline for SVM classifier with optional scaling and preprocessing.\"\"\"\n",
    "    pipe = [\n",
    "        ('SVM', SVC(kernel='linear', probability=True))\n",
    "    ]\n",
    "    if base_pipe:\n",
    "        pipe = base_pipe + pipe\n",
    "    return Pipeline(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020fc194",
   "metadata": {},
   "source": [
    "# 2: Creating Grid Search Presets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78a63e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "\n",
    "def get_preprocessing_grid_search(pipe):\n",
    "    \"\"\"Returns a GridSearchCV *argument* for the preprocessing pipeline. Should be combined with another pipeline component.\"\"\"\n",
    "    # Define the parameter grid for PCA/ICA and scaling\n",
    "    param_grid = {\n",
    "        'Scaler': [StandardScaler(), None],\n",
    "    }\n",
    "    if 'PCA' in pipe.named_steps:\n",
    "        param_grid['PCA__n_components'] = [2, 3, 4, 5]\n",
    "        param_grid['PCA__random_state'] = [42]\n",
    "    if 'ICA' in pipe.named_steps:\n",
    "        param_grid['ICA__n_components'] = [2, 3, 4, 5]\n",
    "        param_grid['ICA__random_state'] = [42]\n",
    "    \n",
    "    return param_grid\n",
    "\n",
    "def get_knn_grid_search(pipe, base_grid = None, scoring='accuracy', cv=StratifiedKFold(5)):\n",
    "    \"\"\"Returns a GridSearchCV object for KNN classifier with a parameter grid.\"\"\"\n",
    "    # Define the parameter grid for KNN\n",
    "    param_grid = {\n",
    "        'KNN__n_neighbors': [3, 5, 7, 9],\n",
    "        'KNN__weights': ['uniform', 'distance'],\n",
    "        'KNN__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    }\n",
    "    \n",
    "    if base_grid:\n",
    "        # Merge the base grid with the KNN grid\n",
    "        param_grid = {**base_grid, **param_grid}\n",
    "    \n",
    "    # Create a GridSearchCV object\n",
    "    knn_grid_search = GridSearchCV(estimator=pipe,param_grid=param_grid,scoring=scoring,cv=cv,n_jobs=-1)\n",
    "    \n",
    "    return knn_grid_search\n",
    "\n",
    "def get_naive_bayes_grid_search(pipe, base_grid = None, scoring='accuracy', cv=StratifiedKFold(5)):\n",
    "    \"\"\"Returns a GridSearchCV object for Naive Bayes classifiers with a parameter grid.\"\"\"\n",
    "    param_grid = [\n",
    "    {\n",
    "        'clf': [GaussianNB()],\n",
    "        'clf__var_smoothing': [1e-9, 1e-8, 1e-7]\n",
    "    },\n",
    "    {\n",
    "        'clf': [MultinomialNB()],\n",
    "        'clf__alpha': [0.5, 1.0, 1.5]\n",
    "    },\n",
    "    {\n",
    "        'clf': [BernoulliNB()],\n",
    "        'clf__alpha': [0.5, 1.0],\n",
    "        'clf__binarize': [0.0, 0.5]\n",
    "    }\n",
    "    ]\n",
    "    \n",
    "    if base_grid:\n",
    "        # Merge the base grid with the Naive Bayes grid\n",
    "        param_grid = {**base_grid, **param_grid}\n",
    "    \n",
    "    # Create a GridSearchCV object\n",
    "    nb_grid_search = GridSearchCV(estimator=pipe,param_grid=param_grid,scoring=scoring,cv=cv,n_jobs=-1)\n",
    "    \n",
    "    return nb_grid_search\n",
    "\n",
    "def get_log_reg_grid_search(pipe, base_grid = None, scoring='accuracy', cv=StratifiedKFold(5)):\n",
    "    \"\"\"Returns a GridSearchCV object for Logistic Regression with a parameter grid.\"\"\"\n",
    "    # Define the parameter grid for Logistic Regression\n",
    "    param_grid = {\n",
    "        'LogisticRegression__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'LogisticRegression__penalty': ['l2', None],\n",
    "        'LogisticRegression__solver': ['lbfgs', 'liblinear']\n",
    "    }\n",
    "    \n",
    "    if base_grid:\n",
    "        # Merge the base grid with the Logistic Regression grid\n",
    "        param_grid = {**base_grid, **param_grid}\n",
    "    \n",
    "    # Create a GridSearchCV object\n",
    "    log_reg_grid_search = GridSearchCV(estimator=pipe,param_grid=param_grid,scoring=scoring,cv=cv,n_jobs=1\n",
    "    )\n",
    "    \n",
    "    return log_reg_grid_search\n",
    "\n",
    "def get_decision_tree_grid_search(pipe, base_grid = None, scoring='accuracy', cv=StratifiedKFold(5)):\n",
    "    \"\"\"Returns a GridSearchCV object for Decision Tree classifier with a parameter grid.\"\"\"\n",
    "    # Define the parameter grid for Decision Tree\n",
    "    param_grid = {\n",
    "        'DecisionTree__criterion': ['gini', 'entropy'],\n",
    "        'DecisionTree__max_depth': [None, 5, 10, 15],\n",
    "        'DecisionTree__min_samples_split': [2, 5, 10],\n",
    "        'DecisionTree__min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    \n",
    "    if base_grid:\n",
    "        # Merge the base grid with the Decision Tree grid\n",
    "        param_grid = {**base_grid, **param_grid}\n",
    "    \n",
    "    # Create a GridSearchCV object\n",
    "    dt_grid_search = GridSearchCV(estimator=pipe,param_grid=param_grid,scoring=scoring,cv=cv,n_jobs=-1)\n",
    "    \n",
    "    return dt_grid_search\n",
    "\n",
    "def get_svm_grid_search(pipe, base_grid = None, scoring='accuracy', cv=StratifiedKFold(5)):\n",
    "    \"\"\"Returns a GridSearchCV object for SVM classifier with a parameter grid.\"\"\"\n",
    "    # Define the parameter grid for SVM\n",
    "    param_grid = {\n",
    "        'SVM__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'SVM__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "        'SVM__gamma': ['scale', 'auto']\n",
    "    }\n",
    "    \n",
    "    if base_grid:\n",
    "        # Merge the base grid with the SVM grid\n",
    "        param_grid = {**base_grid, **param_grid}\n",
    "    \n",
    "    # Create a GridSearchCV object\n",
    "    svm_grid_search = GridSearchCV(estimator=pipe,param_grid=param_grid,scoring=scoring,cv=cv,n_jobs=-1)\n",
    "    \n",
    "    return svm_grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "112d870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_preset(pipe_source, grid_search_source):\n",
    "    prep_pipe = get_preprocessing_pipe(scaling=True, preprocessing=\"PCA\")\n",
    "    pipe = pipe_source(prep_pipe)\n",
    "    prep_grid = get_preprocessing_grid_search(pipe)\n",
    "    return grid_search_source(pipe, prep_grid, scoring='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0dc850",
   "metadata": {},
   "source": [
    "# Testing (Unofficial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db0a59d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7012987012987013"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = get_knn_pipe()\n",
    "X_train, X_test, y_train, y_test = get_train_test_diabetes(diabetes_df)\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785aa961",
   "metadata": {},
   "source": [
    "# Model Fitting and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20281806",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_diabetes(diabetes_df, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dd5e7e",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "047e0177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80       100\n",
      "           1       0.63      0.54      0.58        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.70      0.68      0.69       154\n",
      "weighted avg       0.72      0.73      0.72       154\n",
      "\n",
      "Best Parameters: {'KNN__algorithm': 'auto', 'KNN__n_neighbors': 7, 'KNN__weights': 'uniform', 'PCA__n_components': 4, 'PCA__random_state': 42, 'Scaler': StandardScaler()}\n",
      "Best Score: 0.6013411996955929\n"
     ]
    }
   ],
   "source": [
    "grid_search = grid_search_preset(get_knn_pipe, get_knn_grid_search)\n",
    "\n",
    "#----[\n",
    "grid_search.fit(X_train, y_train)\n",
    "#----]\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "#Print classification report for the best model\n",
    "print(\"KNN Report:\")\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebd7d21",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51002e85",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not a mapping",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m grid_search_preset(get_naive_bayes_pipe, get_naive_bayes_grid_search)\n\u001b[1;32m      3\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      5\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m, in \u001b[0;36mgrid_search_preset\u001b[0;34m(pipe_source, grid_search_source)\u001b[0m\n\u001b[1;32m      3\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipe_source(prep_pipe)\n\u001b[1;32m      4\u001b[0m prep_grid \u001b[38;5;241m=\u001b[39m get_preprocessing_grid_search(pipe)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grid_search_source(pipe, prep_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 60\u001b[0m, in \u001b[0;36mget_naive_bayes_grid_search\u001b[0;34m(pipe, base_grid, scoring, cv)\u001b[0m\n\u001b[1;32m     42\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     43\u001b[0m {\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m: [GaussianNB()],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m }\n\u001b[1;32m     56\u001b[0m ]\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_grid:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# Merge the base grid with the Naive Bayes grid\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     param_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbase_grid, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam_grid}\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Create a GridSearchCV object\u001b[39;00m\n\u001b[1;32m     63\u001b[0m nb_grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     64\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mpipe,\n\u001b[1;32m     65\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     69\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not a mapping"
     ]
    }
   ],
   "source": [
    "grid_search = grid_search_preset(get_naive_bayes_pipe, get_naive_bayes_grid_search)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Naive Bayes Scoring:\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968da7da",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5c3bff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search_preset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress_stdout_stderr():\n\u001b[1;32m      7\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mUserWarning\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m     grid_search \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search_preset\u001b[49m(get_log_reg_pipe, get_log_reg_grid_search)\n\u001b[1;32m      9\u001b[0m     grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     10\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_search_preset' is not defined"
     ]
    }
   ],
   "source": [
    "# \"UserWarning: Setting penalty='None' will ignore the C and l1_ratio parameters\"\n",
    "# Repeated warnings coming from logreg grid search can be suppressed with this file \n",
    "# Penalty=None is not supported for the liblinear solver, so 1/4 fail, but that's okay.\n",
    "from remove_warnings import *\n",
    "\n",
    "with suppress_stdout_stderr():\n",
    "    warnings.filterwarnings('ignore', category=UserWarning)\n",
    "    grid_search = grid_search_preset(get_log_reg_pipe, get_log_reg_grid_search)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters Logistic Regression:\", best_params)\n",
    "print(\"Best Score Logistic Regression:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87f4eef",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06869b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Decision Tree: {'DecisionTree__criterion': 'entropy', 'DecisionTree__max_depth': 5, 'DecisionTree__min_samples_leaf': 4, 'DecisionTree__min_samples_split': 2, 'PCA__n_components': 3, 'PCA__random_state': 42, 'Scaler': None}\n",
      "Best Score Decision Tree: 0.7541383446621351\n"
     ]
    }
   ],
   "source": [
    "grid_search = grid_search_preset(get_decision_tree_pipe, get_decision_tree_grid_search)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters Decision Tree:\", best_params)\n",
    "print(\"Best Score Decision Tree:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efa7a95",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc8b7f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search_preset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Support Vector Machines\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search_preset\u001b[49m(get_svm_pipe, get_svm_grid_search)\n\u001b[1;32m      3\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      4\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_search_preset' is not defined"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "grid_search = grid_search_preset(get_svm_pipe, get_svm_grid_search)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters SVM:\", best_params)\n",
    "print(\"Best Score SVM:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de34da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csb320-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
